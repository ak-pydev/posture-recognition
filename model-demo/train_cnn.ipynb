{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from torchvision import models, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d447b8db5b764b3d8e6416031a6b4254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/13853 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'barbell biceps curl', '1': 'bench press', '2': 'chest fly machine', '3': 'deadlift', '4': 'decline bench press', '5': 'hammer curl', '6': 'hip thrust', '7': 'incline bench press', '8': 'lat pulldown', '9': 'lateral raises', '10': 'leg extension', '11': 'leg raises', '12': 'plank', '13': 'pull up', '14': 'push up', '15': 'romanian deadlift', '16': 'russian twist', '17': 'shoulder press', '18': 'squat', '19': 't bar row', '20': 'tricep dips', '21': 'tricep pushdown'}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=\"C:/Users/Aaditya Khanal/OneDrive/Desktop/posture-recognition/image_dataset\")\n",
    "\n",
    "# Label map\n",
    "labels = dataset[\"train\"].features[\"label\"].names\n",
    "id2label = {str(i): label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "train_data = dataset_split[\"train\"]\n",
    "val_data = dataset_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "num_classes = len(labels)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Lambda\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Lambda(lambda image: image.convert(\"RGB\")),  # force RGB mode\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomHFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = item[\"image\"]\n",
    "        label = item[\"label\"]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = CustomHFDataset(train_data, transform=transform)\n",
    "val_dataset = CustomHFDataset(val_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 0.3593, Accuracy 0.9300\n",
      "Epoch 2: Loss 0.0194, Accuracy 0.9970\n",
      "Epoch 3: Loss 0.0057, Accuracy 0.9995\n",
      "Epoch 4: Loss 0.0022, Accuracy 0.9999\n",
      "Epoch 5: Loss 0.0012, Accuracy 1.0000\n",
      "Epoch 6: Loss 0.0008, Accuracy 1.0000\n",
      "Epoch 7: Loss 0.0006, Accuracy 1.0000\n",
      "Epoch 8: Loss 0.0004, Accuracy 1.0000\n",
      "Epoch 9: Loss 0.0003, Accuracy 1.0000\n",
      "Epoch 10: Loss 0.0003, Accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct.double() / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}: Loss {epoch_loss:.4f}, Accuracy {epoch_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "\n",
    "val_acc = correct.double() / len(val_loader.dataset)\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
